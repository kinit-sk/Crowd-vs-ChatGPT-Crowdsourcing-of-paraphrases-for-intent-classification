{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BERT large\n",
    "\n",
    "This is just one run that we repeat 10 times for each dataset (for that change the first code cell and the test dataset load cell and report the mean value of each.\n",
    "\n",
    "For the purpose of debugging, this notebook has been run with both bert large (results reported in our paper) and with distilbert (for smaller gpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# we create temporary file for the dataset, based on what kind of train set we want\n",
    "prompt_0 = pd.read_csv('gpt_datasets/for_train_test/prompt_h_0.csv').reset_index(drop=True)\n",
    "prompt_gpt_0 = pd.read_csv('gpt_datasets/for_train_test/prompt_gpt_0.csv').reset_index(drop=True)\n",
    "\n",
    "prompt_12 = pd.read_csv('gpt_datasets/for_train_test/prompt_h_12.csv').reset_index(drop=True)\n",
    "taboo_12 = pd.read_csv('gpt_datasets/for_train_test/taboo_h_12.csv').reset_index(drop=True)\n",
    "prompt_gpt_12 = pd.read_csv('gpt_datasets/for_train_test/prompt_gpt_12.csv').reset_index(drop=True)\n",
    "taboo_gpt_12 = pd.read_csv('gpt_datasets/for_train_test/taboo_gpt_12.csv').reset_index(drop=True)\n",
    "taboo_gpt_12_with_filt = pd.read_csv('gpt_datasets/for_train_test/taboo_gpt_12_filt.csv').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# replace this for whatever file you want to use in your experiments\n",
    "train_taboo_gpt, test_taboo_gpt = train_test_split(taboo_gpt_12_with_filt, test_size=0.2) # can be exchanged for the split with tabooed samples\n",
    "train_taboo_gpt = train_taboo_gpt.append(prompt_gpt_0)\n",
    "\n",
    "train_taboo_gpt.to_csv('gpt_datasets/for_train_test/tmp/train.csv')\n",
    "test_taboo_gpt.to_csv('gpt_datasets/for_train_test/tmp/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:40:35.105918Z",
     "iopub.status.busy": "2023-05-18T10:40:35.105506Z",
     "iopub.status.idle": "2023-05-18T10:40:35.595973Z",
     "shell.execute_reply": "2023-05-18T10:40:35.594996Z",
     "shell.execute_reply.started": "2023-05-18T10:40:35.105887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a4f44c53a2fe693f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\jance\\.cache\\huggingface\\datasets\\csv\\default-a4f44c53a2fe693f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfb61c603c04cdab691220dd576ae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73987b6be0a34ea6a1b7c5b67cc6f132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\jance\\.cache\\huggingface\\datasets\\csv\\default-a4f44c53a2fe693f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df173cbc5a7b4c38b112826ccaadddaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"gpt_datasets/for_train_test/tmp/train.csv\", \"test\": \"gpt_datasets/for_train_test/tmp/test.csv\"}\n",
    "\n",
    "dataset_train, dataset_test = load_dataset(\"csv\", data_files=data_files, split=['train', 'test'], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:33:06.921438Z",
     "iopub.status.busy": "2023-05-18T10:33:06.920779Z",
     "iopub.status.idle": "2023-05-18T10:33:12.166091Z",
     "shell.execute_reply": "2023-05-18T10:33:12.165033Z",
     "shell.execute_reply.started": "2023-05-18T10:33:06.921403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd7b1fec0f549ddac0993d9e10f43e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d99cbb2e8548b4837845383d1b4977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") #bert-large-uncased\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset_train.map(tokenize_function, batched=True)\n",
    "tokenized_test_datasets = dataset_test.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:33:16.590393Z",
     "iopub.status.busy": "2023-05-18T10:33:16.589364Z",
     "iopub.status.idle": "2023-05-18T10:33:37.352893Z",
     "shell.execute_reply": "2023-05-18T10:33:37.351858Z",
     "shell.execute_reply.started": "2023-05-18T10:33:16.590345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-18T10:33:42.256985Z",
     "iopub.status.busy": "2023-05-18T10:33:42.256599Z",
     "iopub.status.idle": "2023-05-18T10:33:55.393916Z",
     "shell.execute_reply": "2023-05-18T10:33:55.392774Z",
     "shell.execute_reply.started": "2023-05-18T10:33:42.256954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.4.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (21.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.70.12.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (1.3.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (1.21.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (2021.11.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from evaluate) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->evaluate) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jance\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.2.0)\n"
     ]
    }
   ],
   "source": [
    "# only if you dont have the evaluate lib from huggingface, e.g. in the kaggle env\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:33:55.396942Z",
     "iopub.status.busy": "2023-05-18T10:33:55.396544Z",
     "iopub.status.idle": "2023-05-18T10:33:56.431425Z",
     "shell.execute_reply": "2023-05-18T10:33:56.430460Z",
     "shell.execute_reply.started": "2023-05-18T10:33:55.396902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:34:55.460914Z",
     "iopub.status.busy": "2023-05-18T10:34:55.460500Z",
     "iopub.status.idle": "2023-05-18T10:34:57.806589Z",
     "shell.execute_reply": "2023-05-18T10:34:57.805689Z",
     "shell.execute_reply.started": "2023-05-18T10:34:55.460883Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"bert_taboo\")\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"bert_taboo\", evaluation_strategy=\"epoch\", per_device_eval_batch_size=16, per_device_train_batch_size=8, learning_rate=1e-5, num_train_epochs=5, save_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:35:02.707899Z",
     "iopub.status.busy": "2023-05-18T10:35:02.707503Z",
     "iopub.status.idle": "2023-05-18T10:35:07.610978Z",
     "shell.execute_reply": "2023-05-18T10:35:07.610020Z",
     "shell.execute_reply.started": "2023-05-18T10:35:02.707867Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_test_datasets,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:35:10.683245Z",
     "iopub.status.busy": "2023-05-18T10:35:10.682852Z",
     "iopub.status.idle": "2023-05-18T10:38:29.205013Z",
     "shell.execute_reply": "2023-05-18T10:38:29.203402Z",
     "shell.execute_reply.started": "2023-05-18T10:35:10.683208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text.\n",
      "***** Running training *****\n",
      "  Num examples = 4488\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2805' max='2805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2805/2805 12:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>0.139199</td>\n",
       "      <td>0.975940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.052706</td>\n",
       "      <td>0.983459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.042809</td>\n",
       "      <td>0.986466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.038185</td>\n",
       "      <td>0.987970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.987970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 665\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 665\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 665\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 665\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 665\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2805, training_loss=0.20916806818542208, metrics={'train_runtime': 786.9204, 'train_samples_per_second': 28.516, 'train_steps_per_second': 3.565, 'total_flos': 2972992518144000.0, 'train_loss': 0.20916806818542208, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:38:31.291589Z",
     "iopub.status.busy": "2023-05-18T10:38:31.291016Z",
     "iopub.status.idle": "2023-05-18T10:38:32.740246Z",
     "shell.execute_reply": "2023-05-18T10:38:32.739250Z",
     "shell.execute_reply.started": "2023-05-18T10:38:31.291554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a5d5869447a158ce\n",
      "Reusing dataset csv (C:\\Users\\jance\\.cache\\huggingface\\datasets\\csv\\default-a5d5869447a158ce\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "Using custom data configuration default-98f3985ad150b854\n",
      "Reusing dataset csv (C:\\Users\\jance\\.cache\\huggingface\\datasets\\csv\\default-98f3985ad150b854\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "Using custom data configuration default-7bf051d34ce84287\n",
      "Reusing dataset csv (C:\\Users\\jance\\.cache\\huggingface\\datasets\\csv\\default-7bf051d34ce84287\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"gpt_datasets/for_train_test/prompt_gpt_12.csv\", split='train', keep_default_na=False)\n",
    "\n",
    "dct_dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "dataset_prompt_gpt = dct_dataset['test']\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"gpt_datasets/for_train_test/taboo_gpt_12.csv\", split='train', keep_default_na=False)\n",
    "\n",
    "dct_dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "dataset_taboo_human = dct_dataset['test']\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"gpt_datasets/for_train_test/prompt_h_12.csv\", split='train', keep_default_na=False)\n",
    "\n",
    "dct_dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "dataset_prompt_human = dct_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:38:35.102703Z",
     "iopub.status.busy": "2023-05-18T10:38:35.102336Z",
     "iopub.status.idle": "2023-05-18T10:38:36.077607Z",
     "shell.execute_reply": "2023-05-18T10:38:36.076666Z",
     "shell.execute_reply.started": "2023-05-18T10:38:35.102674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdd176699e14012b0268b3c0263a7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35edfbee2ce4a40a024ccfc0cf602a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60049596fd6a49f2b9d4bff28bf693be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_all_gpt = dataset_prompt_gpt.map(tokenize_function, batched=True)\n",
    "tokenized_dataset_taboo_h = dataset_taboo_human.map(tokenize_function, batched=True)\n",
    "tokenized_dataset_all = dataset_prompt_human.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:38:37.637340Z",
     "iopub.status.busy": "2023-05-18T10:38:37.636724Z",
     "iopub.status.idle": "2023-05-18T10:39:21.915332Z",
     "shell.execute_reply": "2023-05-18T10:39:21.914259Z",
     "shell.execute_reply.started": "2023-05-18T10:38:37.637298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 697\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0009535038843750954,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_runtime': 7.5322,\n",
       " 'eval_samples_per_second': 92.536,\n",
       " 'eval_steps_per_second': 11.683,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_dataset_all_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T10:39:21.923000Z",
     "iopub.status.busy": "2023-05-18T10:39:21.922631Z",
     "iopub.status.idle": "2023-05-18T10:40:05.115624Z",
     "shell.execute_reply": "2023-05-18T10:40:05.112767Z",
     "shell.execute_reply.started": "2023-05-18T10:39:21.922967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1188\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2895137369632721,\n",
       " 'eval_accuracy': 0.9326599326599326,\n",
       " 'eval_runtime': 12.3836,\n",
       " 'eval_samples_per_second': 95.934,\n",
       " 'eval_steps_per_second': 12.032,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_dataset_taboo_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-18T10:40:05.119971Z",
     "iopub.status.idle": "2023-05-18T10:40:05.120564Z",
     "shell.execute_reply": "2023-05-18T10:40:05.120339Z",
     "shell.execute_reply.started": "2023-05-18T10:40:05.120312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1130\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1644696593284607,\n",
       " 'eval_accuracy': 0.9690265486725663,\n",
       " 'eval_runtime': 11.9438,\n",
       " 'eval_samples_per_second': 94.61,\n",
       " 'eval_steps_per_second': 11.889,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_dataset_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
