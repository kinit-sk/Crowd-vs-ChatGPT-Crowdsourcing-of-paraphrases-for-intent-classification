{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f9de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc497a",
   "metadata": {},
   "source": [
    "### Now we train (1st SVMs)\n",
    "\n",
    "We use the for_train_test directory for this, so we create the datasets based on splits that were collected.\n",
    "\n",
    "Note that the human datasets are not included in this repo and should be downloaded from the link to the original study. Preprocessing code can be found in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166fbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prompt_0 = pd.read_csv('gpt_datasets/for_train_test/prompt_h_0.csv').reset_index(drop=True)\n",
    "prompt_gpt_0 = pd.read_csv('gpt_datasets/for_train_test/prompt_gpt_0.csv').reset_index(drop=True)\n",
    "\n",
    "prompt_12 = pd.read_csv('gpt_datasets/for_train_test/prompt_h_12.csv').reset_index(drop=True)\n",
    "taboo_12 = pd.read_csv('gpt_datasets/for_train_test/taboo_h_12.csv').reset_index(drop=True)\n",
    "prompt_gpt_12 = pd.read_csv('gpt_datasets/for_train_test/prompt_gpt_12.csv').reset_index(drop=True)\n",
    "taboo_gpt_12 = pd.read_csv('gpt_datasets/for_train_test/taboo_gpt_12.csv').reset_index(drop=True)\n",
    "taboo_gpt_12_with_filt = pd.read_csv('gpt_datasets/for_train_test/taboo_gpt_12_filt.csv').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e22b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "prompt_0['text']=prompt_0['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "prompt_gpt_0['text']=prompt_gpt_0['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "\n",
    "prompt_12['text']=prompt_12['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "taboo_12['text']=taboo_12['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "prompt_gpt_12['text']=prompt_gpt_12['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "taboo_gpt_12['text']=taboo_gpt_12['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "taboo_gpt_12_with_filt['text']=taboo_gpt_12_with_filt['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8ddf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "prompt_0['text']=prompt_0['text'].apply(lambda x: re.sub(' +',' ',x))\n",
    "prompt_gpt_0['text']=prompt_gpt_0['text'].apply(lambda x: re.sub(' +',' ',x))\n",
    "\n",
    "prompt_12['text']=prompt_12['text'].apply(lambda x: re.sub(' +',' ',x))\n",
    "taboo_12['text']=taboo_12['text'].apply(lambda x: re.sub(' +',' ',x))\n",
    "prompt_gpt_12['text']=prompt_gpt_12['text'].apply(lambda x: re.sub(' +',' ',x))\n",
    "taboo_gpt_12['text']=taboo_gpt_12['text'].apply(lambda x: re.sub(' +',' ',x))\n",
    "taboo_gpt_12_with_filt['text']=taboo_gpt_12_with_filt['text'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c1da1",
   "metadata": {},
   "source": [
    "### below just change the train dataset and the test datasets and you are all good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee7bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "same_res = []\n",
    "same_f1 = []\n",
    "\n",
    "same_gpt_res = []\n",
    "same_gpt_f1 = []\n",
    "\n",
    "taboo_res = []\n",
    "taboo_f1 = []\n",
    "\n",
    "taboo_gpt_res = []\n",
    "taboo_gpt_f1 = []\n",
    "\n",
    "for idx in range(0, 10):\n",
    "    \n",
    "    # first get test splits from 1 and 2; then combine the rest into train\n",
    "    \n",
    "    train_same, test_same = train_test_split(prompt_12, test_size=0.2)\n",
    "    train_same = train_same.append(prompt_0)\n",
    "    \n",
    "    train_taboo, test_taboo = train_test_split(taboo_12, test_size=0.2)\n",
    "    train_taboo = train_taboo.append(prompt_0)\n",
    "    \n",
    "    train_same_gpt, test_same_gpt = train_test_split(prompt_gpt_12, test_size=0.2)\n",
    "    train_same_gpt = train_same_gpt.append(prompt_gpt_0)\n",
    "    \n",
    "    train_taboo_gpt, test_taboo_gpt = train_test_split(taboo_gpt_12, test_size=0.2) # can be exchanged for the split with tabooed samples\n",
    "    train_taboo_gpt = train_taboo_gpt.append(prompt_gpt_0)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "            ('bow', CountVectorizer()),  \n",
    "            ('tfidf', TfidfTransformer()),  \n",
    "            ('c', svm.SVC(probability=True))\n",
    "        ])\n",
    "    fit = pipeline.fit(train_taboo['text'].str.lower(), train_taboo['label'])\n",
    "    \n",
    "    pred=pipeline.predict(test_same['text'].str.lower())\n",
    "    same_res.append(accuracy_score(pred,test_same['label']))\n",
    "    same_f1.append(f1_score(pred,test_same['label'],  average = 'weighted'))\n",
    "    \n",
    "    pred=pipeline.predict(test_same_gpt['text'].str.lower())\n",
    "    same_gpt_res.append(accuracy_score(pred,test_same_gpt['label']))\n",
    "    same_gpt_f1.append(f1_score(pred,test_same_gpt['label'],  average = 'weighted'))\n",
    "        \n",
    "    pred=pipeline.predict(test_taboo['text'].str.lower())\n",
    "    taboo_res.append(accuracy_score(pred,test_taboo['label']))\n",
    "    taboo_f1.append(f1_score(pred,test_taboo['label'],  average = 'weighted'))\n",
    "        \n",
    "    pred=pipeline.predict(test_taboo_gpt['text'].str.lower())\n",
    "    taboo_gpt_res.append(accuracy_score(pred,test_taboo_gpt['label']))\n",
    "    taboo_gpt_f1.append(f1_score(pred,test_taboo_gpt['label'],  average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89eef81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC SAME MEAN: 0.9665364583333333 STD: 0.005647200115156623\n",
      "F1 SAME MEAN: 0.9665461587404192 STD: 0.005619698126697387\n",
      "ACC GPT SAME MEAN: 0.997872340425532 STD: 0.001822018805484418\n",
      "F1 GPT SAME MEAN: 0.9978702053023847 STD: 0.0018244993888413507\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(same_res)\n",
    "\n",
    "print(\"ACC SAME MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr)))\n",
    "\n",
    "arr = np.array(same_f1)\n",
    "\n",
    "print(\"F1 SAME MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr))) \n",
    "\n",
    "arr = np.array(same_gpt_res)\n",
    "\n",
    "print(\"ACC GPT SAME MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr)))\n",
    "\n",
    "arr = np.array(same_gpt_f1)\n",
    "\n",
    "print(\"F1 GPT SAME MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8918f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC TABOO MEAN: 0.8397698209718669 STD: 0.012569103082045013\n",
      "F1 TABOO MEAN: 0.8416977794559694 STD: 0.012121111024673689\n",
      "ACC GPT TABOO MEAN: 0.9791831357048748 STD: 0.002751068908803825\n",
      "F1 GPT TABOO MEAN: 0.9791853936117191 STD: 0.00274839346599952\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(taboo_res)\n",
    "\n",
    "print(\"ACC TABOO MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr)))\n",
    "\n",
    "arr = np.array(taboo_f1)\n",
    "\n",
    "print(\"F1 TABOO MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr))) \n",
    "\n",
    "arr = np.array(taboo_gpt_res)\n",
    "\n",
    "print(\"ACC GPT TABOO MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr)))\n",
    "\n",
    "arr = np.array(taboo_gpt_f1)\n",
    "\n",
    "print(\"F1 GPT TABOO MEAN: \" + str(np.mean(arr)) + \" STD: \" + str(np.std(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98dfaed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
